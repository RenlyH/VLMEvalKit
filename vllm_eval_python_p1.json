{
  "model": {
    "vllm-code_v3.1_32B_step88_sp": {
      "class": "LMDeployAPIWithToolUse",
      "api_base": "http://0.0.0.0:8000/v1/chat/completions",
      "temperature": 0.0,
      "retry": 10,
      "use_tool": true,
      "tool_start_token": "<code>",
      "tool_end_token": "</code>",
      "system_prompt": "You are a helpful assistant. - You can generate Python script to get intermediate results to assist you answer.\n- Script will be executed automatically and the execution output (printed text or cropped images) will be returned as your next input.\n- You need to analyze the execution output and decide whether to answer the question or continue generating python script.\n\n# Instruction to generate python script\n - Write executable Python script. Wrap code in <code> … </code>.\n - If you need to operate on the provided image, you should load it with predefined object: 'path_to_image' in the execution environment. \n - To get the execution results: You need to use print() for text output and Image.show() to display a modified image (crop, rotate, etc).\n\nlimits:\n  - Max image show: 2 images\n\nTo answer the question, you need think step by step and put your thought in <think>…</think>. Then, you should either answer directly and put answer in <answer> … </answer> or write python script to get more results and put python code in  <code> … </code>.\n"
    }
  },
  "data": {
    "MMMU_DEV_VAL":{
      "class": "MMMUDataset",
      "dataset": "MMMU_DEV_VAL"
    },
    "MathVista_MINI": {
      "class": "MathVista",
      "dataset": "MathVista_MINI"
    },
    "VStarBench": {
      "class": "ImageMCQDataset",
      "dataset": "VStarBench"
    },
    "CharXiv_descriptive_val":{
      "class": "CharXiv",
      "dataset": "CharXiv_descriptive_val"
    },
    "CharXiv_reasoning_val":{
      "class": "CharXiv",
      "dataset": "CharXiv_reasoning_val"
    },
    "VLMBlind":{
      "class": "VLMBlind",
      "dataset": "VLMBlind"
    }
  }
}